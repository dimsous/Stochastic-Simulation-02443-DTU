{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Integral's exact solution: 1.718281828459045\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import statistics as st\n",
    "\n",
    "print(\"\\nIntegral's exact solution:\",np.exp(1)-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Estimate the integral of the exponential function from 0 to 1 by simulation (the crude Monte Carlo estimator). Use eg. an estimator based on 100 samples and present the result as the point estimator and a confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7983227765189471 0.2945747418315329 1.7082139898841489 1.8884315631537454\n"
     ]
    }
   ],
   "source": [
    "def cmc(n):\n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        u = np.random.uniform(0,1)\n",
    "        x.append(np.exp(u))\n",
    "    res = sum(x)/n\n",
    "    var = np.var(x)\n",
    "    return res, var\n",
    "\n",
    "res, var = cmc(100)\n",
    "lb = res - stats.t.ppf(0.95, 100) * (math.sqrt(var)/math.sqrt(100))\n",
    "ub = res + stats.t.ppf(0.95, 100) * (math.sqrt(var)/math.sqrt(100))\n",
    "print(res,var,lb,ub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Estimate the integral of the exponential function from 0 to 1 using antithetic variables, with comparable computer ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7268817909405243 0.004100966096902039 1.716249851888876 1.7375137299921726\n"
     ]
    }
   ],
   "source": [
    "def av(n):\n",
    "    x= []\n",
    "    for i in range(n):\n",
    "        u = np.random.uniform(0,1)\n",
    "        y = (np.exp(u)+np.exp(1-u))/2\n",
    "        x.append(y)\n",
    "    res = sum(x)/n\n",
    "    var = np.var(x)\n",
    "    return res, var\n",
    "\n",
    "res, var = av(100)\n",
    "lb = res - stats.t.ppf(0.95, 100) * (math.sqrt(var)/math.sqrt(100))\n",
    "ub = res + stats.t.ppf(0.95, 100) * (math.sqrt(var)/math.sqrt(100))\n",
    "print(res,var,lb,ub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Estimate the integral of the exponential function from 0 to 1 using a control variable, with comparable computer ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.716161951209148 0.003431013180648312 1.706437153366154 1.725886749052142\n"
     ]
    }
   ],
   "source": [
    "def cv(n):\n",
    "    z = []\n",
    "    u = np.random.uniform(0,1,n)\n",
    "    c = -np.cov(u,np.exp(u))[0, 1]/np.var(u)\n",
    "    for i in range(n):\n",
    "        z.append(np.exp(u[i])+c*(u[i]-0.5))\n",
    "    res = sum(z)/n\n",
    "    var = np.var(z)\n",
    "    return res, var\n",
    "\n",
    "res, var = cv(100)\n",
    "lb = res - stats.t.ppf(0.95, 100) * (math.sqrt(var)/math.sqrt(100))\n",
    "ub = res + stats.t.ppf(0.95, 100) * (math.sqrt(var)/math.sqrt(100))\n",
    "print(res,var,lb,ub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Estimate the integral of the exponential function from 0 to 1 using stratified sampling, with comparable computer ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.732224633253939 2.837749652480999e-06 1.7319449564626046 1.7325043100452735\n"
     ]
    }
   ],
   "source": [
    "def strat(n, m):\n",
    "    w = []\n",
    "    for i in range(n):\n",
    "        wi = 0\n",
    "        for j in range(m):\n",
    "            u = np.random.uniform(j/m, (j + 1)/m)\n",
    "            wi += np.exp(j/m+u/m)\n",
    "        w.append(wi/m)\n",
    "    res = sum(w)/n\n",
    "    var = np.var(w)\n",
    "    return res, var\n",
    "\n",
    "res, var = strat(100, 10)\n",
    "lb = res - stats.t.ppf(0.95, 100) * (math.sqrt(var)/math.sqrt(100))\n",
    "ub = res + stats.t.ppf(0.95, 100) * (math.sqrt(var)/math.sqrt(100))\n",
    "print(res,var,lb,ub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use control variates to reduce the variance of the estimator in exercise 4 (Poisson arrivals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9610225520991113e-05\n"
     ]
    }
   ],
   "source": [
    "su = 10; mst = 8; mct = 1; c = 10000; n = 10\n",
    "\n",
    "def bc1(su, mst, mct, c):\n",
    "    res = 0\n",
    "    t = np.cumsum(np.random.exponential(mct, c))\n",
    "    st = [0] * su\n",
    "    for i in range(c):\n",
    "        if t[i] > min(st):\n",
    "            st[st.index(min(st))] = np.random.exponential(mst) + t[i]\n",
    "        else:\n",
    "            res +=1\n",
    "    return res/c, np.mean(t)\n",
    "\n",
    "res = [bc1(su, mst, mct, c) for i in range(n)]\n",
    "x,y = zip(*res)\n",
    "\n",
    "def cv2(x,y):\n",
    "    c = -np.cov(x,y)[0, 1]/np.var(y)\n",
    "    res = x+c*(y-np.mean(y))\n",
    "    var = np.var(res)\n",
    "    return res, var\n",
    "\n",
    "res, var = cv2(x, y)\n",
    "print(var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Demonstrate the effect of using common random numbers in exercise 4 for the difference between Poisson arrivals (Part 1) and a renewal process with hyperexponential interarrival times."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. For a standard normal random variable Z ∼ N(0, 1) using the crude Monte Carlo estimator estimate the probability Z > a. Then try importance sampling with a normal density with mean a and\n",
    "variance σ2. For the expirements start using σ2 = 1, use different values of a (e.g. 2 and 4), and different sample sizes. If time permits experiment with other values for σ2. Finally discuss the\n",
    "efficiency of the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Expected Probability 0.15865525393145707\n",
      "\n",
      " crude Monte Carlo: 0.1632 0.15839898632708352\n",
      "\n",
      " Importance Sampling: 0.1596074398939642\n"
     ]
    }
   ],
   "source": [
    "n = 10000; a = 1; sigma = 1\n",
    "exp_prob = 1-stats.norm.cdf(a, 0, 1)\n",
    "\n",
    "def cmc1(n,a):\n",
    "    u = np.random.uniform(size=n)\n",
    "    N = stats.norm.ppf(u)\n",
    "    res = sum(N>a)/n\n",
    "    return res\n",
    "\n",
    "res1 = cmc1(n,a)\n",
    "\n",
    "def cmc2(n,a):\n",
    "    u = np.random.uniform(size=n)\n",
    "    z = 1/(np.sqrt(2*np.pi))*(a)/(u**2)*np.exp(-0.5*(a/u)**2)\n",
    "    res = sum(z)/n\n",
    "    return res\n",
    "\n",
    "res2 = cmc2(n,a)\n",
    "\n",
    "def imps1(n, a, sigma):\n",
    "    y = np.random.normal(a, sigma, n)\n",
    "    h = y>a\n",
    "    f = stats.norm.pdf(y)\n",
    "    g = stats.norm.pdf(y, a, sigma)\n",
    "    res = sum(h*f/g)/n\n",
    "    return res\n",
    "\n",
    "res3 = imps1(n, a, sigma)\n",
    "\n",
    "print(\"\\n Expected Probability\", exp_prob)\n",
    "print(\"\\n Crude Monte Carlo:\", res1, res2)\n",
    "print(\"\\n Importance Sampling:\", res3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Use importance sampling with g(x) = λ exp (−λ ∗ x) to calculate the integral  of Question 1. Try to find the optimal value of λ by calculating the variance of h(X)f(X)/g(X) and verify by simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lambda for which IS estimator approaches the exact solution: 3.8037803780378034\n",
      "Corresponding integral value and variance: 1.7182297430783398 21.719947569201505\n",
      "Simulated values: (1.6887181755409053, 21.32714176134239)\n",
      "\n",
      "Lambda that minimises variance: 1.0054005400540054\n",
      "Corresponding integral value and minimum variance: 2.576925082822111 2.990418031211429\n",
      "Simulated values: (2.6435157874081994, 3.1454635908486925)\n"
     ]
    }
   ],
   "source": [
    "def imps2(l, n):\n",
    "    u = np.random.uniform(size=n)\n",
    "    y = l*np.exp(-l*u)\n",
    "    #y = stats.expon.ppf(u, scale=1/l)\n",
    "    h = np.exp(y)\n",
    "    f = y * (y <= 1)\n",
    "    g = l*np.exp(-l*y)\n",
    "    #g = stats.expon.pdf(y, scale=1/l)\n",
    "    res = sum(h*f/g)/n\n",
    "    var = np.var(h*f/g)\n",
    "    return res, var\n",
    "\n",
    "n=10000\n",
    "ls = np.linspace(1, 10, 10000)\n",
    "varl = []\n",
    "resl = []\n",
    "error = 300\n",
    "optres = 0\n",
    "optvar = 0\n",
    "for l in ls:\n",
    "    res, var = imps2(l, n)\n",
    "    resl.append(res)\n",
    "    varl.append(var)\n",
    "    new_error = np.abs(res-(np.exp(1)-1))\n",
    "    if new_error<error:\n",
    "        error = new_error\n",
    "        optres = res\n",
    "        optvar = var\n",
    "        optl1 = l\n",
    "\n",
    "print(\"\\nLambda for which IS estimator approaches the exact solution:\", optl1)\n",
    "print(\"Corresponding integral value and variance:\",optres,optvar)\n",
    "print(\"Simulated values:\",imps2(optl1,n))\n",
    "\n",
    "optl2 = ls[np.argmin(varl)]\n",
    "print(\"\\nLambda that minimises variance:\", optl2)\n",
    "print(\"Corresponding integral value and minimum variance:\",resl[np.argmin(varl)],min(varl))\n",
    "print(\"Simulated values:\",imps2(optl2,n))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. For the Pareto case derive the IS estimator for the mean using the first moment distribution as sampling distribution. Is the approach meaningful? and could this be done in general? With this insight could you change the choice of g(x) in the previous question (Question 8) such that importance sampling would reduce the variance? You do not need to implement this, as long as you can argue, what should happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9846659970952385"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def imps3(n,b,k):\n",
    "    u = np.random.uniform(size=n)\n",
    "    y = stats.pareto.ppf(u, b, loc=0, scale=k)\n",
    "    h = np.mean(y)\n",
    "    f = stats.pareto.pdf(y, b, loc=0, scale=k) \n",
    "    g = k*b/(k-1)\n",
    "    return np.sum(h*f/g)/n\n",
    "imps3(10000,1,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
